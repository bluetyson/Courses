\documentclass[]{article}
\usepackage{mathtools,amsmath,amssymb,amsthm,mathrsfs}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{listings}
\title{Assignment 2}
\author{Dilawar Singh}
\date{\today}

\begin{document}
\maketitle

\paragraph{Problem 1}

Given a joint distribution, calculate various quantities:

\begin{tabular}[c]{l|c c}
\(y/x\) & 0 & 1 \\
\hline
0 & 1/4 & 1/4 \\
1 & 0 & 1/2 \\
\hline
\end{tabular}

\begin{enumerate}
\item H(X,Y)
\item H(X)
\item H(Y)
\item H(X\textbar{}Y)
\item H(Y\textbar{}X)
\item H(X) + H(Y) - H(X,Y)
\item H(X) - H(X\textbar{}Y)
\item H(Y) - H(Y\textbar{}X)
\item I(X;Y)
\end{enumerate}

\paragraph*{Solution}

Attached Haskell script computes these quantities. These output is below:

\begin{lstlisting}
H(X,Y) = 1.5 
H(X) = 0.8112781
H(Y) = 1.0
H(X|Y) = 0.5
H(Y|X) = 0.68872184
H(X) + H(Y) - H(X,Y) = 0.3112781
H(X) - H(X|Y) = 0.3112781
H(Y) - H(Y|X) = 0.31127816
I(X;Y) = H(X) - H(X,Y) = 0.3112781
Solved all
\end{lstlisting}

The script is following.
\lstinputlisting[language=Haskell,basicstyle=\tiny]{./problem1.hs}

\paragraph{Problem 2}

Revisit Problem 2 from HW1, but now armed with the definition of mutual
information. Set up a table where each row Y corresponds to the potential
outcome of the experiment (L, B, R for left-heavy, balanced, or right-heavy) and
each column X corresponds to each of the 25 equally likely options (1 – 12 for
one coin heavy; 13 – 24 for one coin light; 25 for no counterfeit).  Suppose the
first weighing involves two sets of a coins, for a = 1, ... , 6 . Set up the
correct joint distribution in each case. Calculate the mutual information
I(X;Y). This tells you how many bits of information your measurement provides.
What is the most informative measurement?

\end{document}
